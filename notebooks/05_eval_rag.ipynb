{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.chromadb_rm import ChromadbRM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerateAnswer(dspy.Signature):\n",
    "    \"\"\"Answer questions given the context\"\"\"\n",
    "\n",
    "    context = dspy.InputField(desc=\"may contain relevant facts\")\n",
    "    question = dspy.InputField()\n",
    "    answer = dspy.OutputField(desc=\"Short factual answer to the question. 1 - 5 words long.\")\n",
    "\n",
    "class RAG(dspy.Module):\n",
    "    def __init__(self, num_passages=5):\n",
    "        super().__init__()\n",
    "        self.retrieve = dspy.Retrieve(k=num_passages)\n",
    "        self.generate_answer = dspy.ChainOfThought(GenerateAnswer)\n",
    "    \n",
    "    def forward(self, question):\n",
    "        context = self.retrieve(question).passages\n",
    "        prediction = self.generate_answer(context=context, question=question)\n",
    "        return dspy.Prediction(context=context, answer=prediction.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup():\n",
    "    \"\"\"\n",
    "    Setup the dsypy and retrieval models\n",
    "    \"\"\"\n",
    "\n",
    "    turbo = dspy.OpenAI(model='gpt-3.5-turbo')\n",
    "\n",
    "    chroma_rm = ChromadbRM(collection_name=\"test\", persist_directory=\"chroma.db\", local_embed_model=\"sentence-transformers/paraphrase-MiniLM-L6-v2\",\n",
    "                                   openai_api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "\n",
    "    dspy.settings.configure(lm=turbo, rm=chroma_rm)\n",
    "    \n",
    "    rag = RAG()\n",
    "\n",
    "    return rag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection Count: 3789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sudhanva/miniconda3/lib/python3.11/site-packages/torch/cuda/__init__.py:138: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at /opt/conda/conda-bld/pytorch_1702400430266/work/c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "rag = setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read question, ground_truths from ./data/processed/synthetic_dataset.csv\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"./data/processed/synthetic_dataset.csv\")\n",
    "\n",
    "df = df[['question', 'ground_truths']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>ground_truths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Who directed the play \"How to Curse\" in 2007?</td>\n",
       "      <td>['Josie Rourke']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Who directed the film \"Donkey Punch\"?</td>\n",
       "      <td>['Olly Blackburn.']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Who was Du Fu's paternal grandfather?</td>\n",
       "      <td>['Du Shenyan.']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How many children did Du Fu have by 757?</td>\n",
       "      <td>['Five.']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Where did Du Fu spend most of the next five ye...</td>\n",
       "      <td>['Sichuan province.']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question          ground_truths\n",
       "0      Who directed the play \"How to Curse\" in 2007?       ['Josie Rourke']\n",
       "1              Who directed the film \"Donkey Punch\"?    ['Olly Blackburn.']\n",
       "2              Who was Du Fu's paternal grandfather?        ['Du Shenyan.']\n",
       "3           How many children did Du Fu have by 757?              ['Five.']\n",
       "4  Where did Du Fu spend most of the next five ye...  ['Sichuan province.']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into train and test\n",
    "train, test = train_test_split(df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the train and test data\n",
    "train.to_csv(\"./data/processed/train_synthetic.csv\", index=False)\n",
    "test.to_csv(\"./data/processed/test_synthetic.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "# Create an empty list to store rows\n",
    "eval_results_rows = []\n",
    "\n",
    "for index, row in test.iterrows():\n",
    "    # Get the question\n",
    "    question = row['question']\n",
    "    # Response from rag\n",
    "    response = rag(question)\n",
    "    # Create a dictionary to represent a row\n",
    "    row_dict = {'question': question, 'contexts': response.context, 'answer': response.answer, 'ground_truths' : row['ground_truths']}\n",
    "    # Append the row dictionary to the list\n",
    "    eval_results_rows.append(row_dict)\n",
    "\n",
    "# Create the df_eval_results DataFrame from the list of rows\n",
    "df_eval_results = pd.DataFrame(eval_results_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>contexts</th>\n",
       "      <th>answer</th>\n",
       "      <th>ground_truths_x</th>\n",
       "      <th>ground_truths_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Who directed the play \"How to Curse\" in 2007?</td>\n",
       "      <td>[in 2006, boulter starred alongside whishaw in...</td>\n",
       "      <td>Josie Rourke</td>\n",
       "      <td>[Josie Rourke]</td>\n",
       "      <td>['Josie Rourke']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Who directed the film \"Donkey Punch\"?</td>\n",
       "      <td>[. turan agreed that mendes'choice of collabor...</td>\n",
       "      <td>Oliver Blackburn.</td>\n",
       "      <td>[Olly Blackburn.]</td>\n",
       "      <td>['Olly Blackburn.']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is Du Fu known for writing extensively ab...</td>\n",
       "      <td>[criticism of du fu's works has focused on his...</td>\n",
       "      <td>Lushi.</td>\n",
       "      <td>[Domestic life, calligraphy, paintings, animals.]</td>\n",
       "      <td>['Domestic life, calligraphy, paintings, anima...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Which chart did \"Kiss You\" debut on in the Uni...</td>\n",
       "      <td>[. it peaked at number 13 in its third and fou...</td>\n",
       "      <td>Billboard</td>\n",
       "      <td>[United States Billboard Hot 100.]</td>\n",
       "      <td>['United States Billboard Hot 100.']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Who held the Vevo record for the most views in...</td>\n",
       "      <td>[the music video garnered 10 @. @ 4 million vi...</td>\n",
       "      <td>Justin Bieber.</td>\n",
       "      <td>[Justin Bieber]</td>\n",
       "      <td>['Justin Bieber']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Who ordered No. 202 Squadron RAF to Gibraltar?</td>\n",
       "      <td>[. the raf dispatched their next squadron to g...</td>\n",
       "      <td>No. 202 Squadron RAF was ordered to Gibraltar.</td>\n",
       "      <td>[Admiralty]</td>\n",
       "      <td>['Admiralty']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Who was the senior tunnel guide with the Royal...</td>\n",
       "      <td>[work in gibraltar began immediately under com...</td>\n",
       "      <td>Pete Jackson.</td>\n",
       "      <td>[Sergeant Major Pete Jackson.]</td>\n",
       "      <td>['Sergeant Major Pete Jackson.']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Who was the Roman Emperor after Nerva?</td>\n",
       "      <td>[nerva ( latin : marcus cocceius nerva caesar ...</td>\n",
       "      <td>Trajan</td>\n",
       "      <td>[Trajan]</td>\n",
       "      <td>['Trajan']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Who was proclaimed emperor after the assassina...</td>\n",
       "      <td>[on 18 september, 96, domitian was assassinate...</td>\n",
       "      <td>Marcus Cocceius Nerva</td>\n",
       "      <td>[Marcus Cocceius Nerva.]</td>\n",
       "      <td>['Marcus Cocceius Nerva.']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Who does Eddie meet at the local bus terminal?</td>\n",
       "      <td>[. as a radio broadcaster, he is remembered fo...</td>\n",
       "      <td>Sarah Packard</td>\n",
       "      <td>[Sarah Packard]</td>\n",
       "      <td>['Sarah Packard']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             question  \\\n",
       "0       Who directed the play \"How to Curse\" in 2007?   \n",
       "1               Who directed the film \"Donkey Punch\"?   \n",
       "2   What is Du Fu known for writing extensively ab...   \n",
       "3   Which chart did \"Kiss You\" debut on in the Uni...   \n",
       "4   Who held the Vevo record for the most views in...   \n",
       "..                                                ...   \n",
       "82     Who ordered No. 202 Squadron RAF to Gibraltar?   \n",
       "83  Who was the senior tunnel guide with the Royal...   \n",
       "84             Who was the Roman Emperor after Nerva?   \n",
       "85  Who was proclaimed emperor after the assassina...   \n",
       "86     Who does Eddie meet at the local bus terminal?   \n",
       "\n",
       "                                             contexts  \\\n",
       "0   [in 2006, boulter starred alongside whishaw in...   \n",
       "1   [. turan agreed that mendes'choice of collabor...   \n",
       "2   [criticism of du fu's works has focused on his...   \n",
       "3   [. it peaked at number 13 in its third and fou...   \n",
       "4   [the music video garnered 10 @. @ 4 million vi...   \n",
       "..                                                ...   \n",
       "82  [. the raf dispatched their next squadron to g...   \n",
       "83  [work in gibraltar began immediately under com...   \n",
       "84  [nerva ( latin : marcus cocceius nerva caesar ...   \n",
       "85  [on 18 september, 96, domitian was assassinate...   \n",
       "86  [. as a radio broadcaster, he is remembered fo...   \n",
       "\n",
       "                                            answer  \\\n",
       "0                                     Josie Rourke   \n",
       "1                                Oliver Blackburn.   \n",
       "2                                           Lushi.   \n",
       "3                                        Billboard   \n",
       "4                                   Justin Bieber.   \n",
       "..                                             ...   \n",
       "82  No. 202 Squadron RAF was ordered to Gibraltar.   \n",
       "83                                   Pete Jackson.   \n",
       "84                                          Trajan   \n",
       "85                           Marcus Cocceius Nerva   \n",
       "86                                   Sarah Packard   \n",
       "\n",
       "                                      ground_truths_x  \\\n",
       "0                                      [Josie Rourke]   \n",
       "1                                   [Olly Blackburn.]   \n",
       "2   [Domestic life, calligraphy, paintings, animals.]   \n",
       "3                  [United States Billboard Hot 100.]   \n",
       "4                                     [Justin Bieber]   \n",
       "..                                                ...   \n",
       "82                                        [Admiralty]   \n",
       "83                     [Sergeant Major Pete Jackson.]   \n",
       "84                                           [Trajan]   \n",
       "85                           [Marcus Cocceius Nerva.]   \n",
       "86                                    [Sarah Packard]   \n",
       "\n",
       "                                      ground_truths_y  \n",
       "0                                    ['Josie Rourke']  \n",
       "1                                 ['Olly Blackburn.']  \n",
       "2   ['Domestic life, calligraphy, paintings, anima...  \n",
       "3                ['United States Billboard Hot 100.']  \n",
       "4                                   ['Justin Bieber']  \n",
       "..                                                ...  \n",
       "82                                      ['Admiralty']  \n",
       "83                   ['Sergeant Major Pete Jackson.']  \n",
       "84                                         ['Trajan']  \n",
       "85                         ['Marcus Cocceius Nerva.']  \n",
       "86                                  ['Sarah Packard']  \n",
       "\n",
       "[87 rows x 5 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "# df_eval_results ground_truths to list\n",
    "df_eval_results['ground_truths'] = df_eval_results['ground_truths'].apply(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the df_eval_results DataFrame to a csv file\n",
    "import time\n",
    "EXP_NAME = \"SIMPLE_RAG\"\n",
    "TIMESTAMP = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "df_eval_results.to_csv('./results/inference_' + EXP_NAME + '_' + TIMESTAMP + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, that we have answers for all the questions, we can evaluate the RAG model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [context_precision]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:25<00:00,  4.17s/it]\n",
      "/home/sudhanva/miniconda3/lib/python3.11/site-packages/datasets/table.py:1395: FutureWarning: promote has been superseded by mode='default'.\n",
      "  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]\n",
      "/home/sudhanva/miniconda3/lib/python3.11/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [faithfulness]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:32<00:00,  5.49s/it]\n",
      "/home/sudhanva/miniconda3/lib/python3.11/site-packages/datasets/table.py:1395: FutureWarning: promote has been superseded by mode='default'.\n",
      "  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]\n",
      "/home/sudhanva/miniconda3/lib/python3.11/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [answer_relevancy]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:52<00:00,  8.70s/it]\n",
      "/home/sudhanva/miniconda3/lib/python3.11/site-packages/datasets/table.py:1395: FutureWarning: promote has been superseded by mode='default'.\n",
      "  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]\n",
      "/home/sudhanva/miniconda3/lib/python3.11/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [context_recall]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:14<00:00,  2.46s/it]\n",
      "/home/sudhanva/miniconda3/lib/python3.11/site-packages/datasets/table.py:1395: FutureWarning: promote has been superseded by mode='default'.\n",
      "  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]\n",
      "/home/sudhanva/miniconda3/lib/python3.11/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [answer_similarity]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:06<00:00,  1.13s/it]\n",
      "/home/sudhanva/miniconda3/lib/python3.11/site-packages/datasets/table.py:1395: FutureWarning: promote has been superseded by mode='default'.\n",
      "  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]\n",
      "/home/sudhanva/miniconda3/lib/python3.11/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [context_relevancy]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:16<00:00,  2.69s/it]\n",
      "/home/sudhanva/miniconda3/lib/python3.11/site-packages/datasets/table.py:1395: FutureWarning: promote has been superseded by mode='default'.\n",
      "  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]\n",
      "/home/sudhanva/miniconda3/lib/python3.11/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    }
   ],
   "source": [
    "from ragas.metrics import (\n",
    "    answer_relevancy,\n",
    "    faithfulness,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    "    answer_similarity,\n",
    "    context_relevancy\n",
    ")\n",
    "from datasets import Dataset\n",
    "from ragas import evaluate\n",
    "\n",
    "ds = Dataset.from_pandas(df_eval_results)\n",
    "\n",
    "result = evaluate(\n",
    "    ds,\n",
    "    metrics=[\n",
    "        context_precision,\n",
    "        faithfulness,\n",
    "        answer_relevancy,\n",
    "        context_recall,\n",
    "        answer_similarity,\n",
    "        context_relevancy\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context_precision': 0.5991, 'faithfulness': 0.7126, 'answer_relevancy': 0.8544, 'context_recall': 0.7835, 'answer_similarity': 0.9124, 'context_relevancy': 0.1115}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sudhanva/miniconda3/lib/python3.11/site-packages/datasets/table.py:1395: FutureWarning: promote has been superseded by mode='default'.\n",
      "  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]\n",
      "/home/sudhanva/miniconda3/lib/python3.11/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    }
   ],
   "source": [
    "# save the result\n",
    "result.to_pandas().to_csv('./results/evaluation_' + EXP_NAME + '_' + TIMESTAMP + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sudhanva/miniconda3/lib/python3.11/site-packages/datasets/table.py:1395: FutureWarning: promote has been superseded by mode='default'.\n",
      "  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]\n",
      "/home/sudhanva/miniconda3/lib/python3.11/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>contexts</th>\n",
       "      <th>answer</th>\n",
       "      <th>ground_truths</th>\n",
       "      <th>context_precision</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>context_recall</th>\n",
       "      <th>answer_similarity</th>\n",
       "      <th>context_relevancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Who directed the play \"How to Curse\" in 2007?</td>\n",
       "      <td>[in 2006, boulter starred alongside whishaw in...</td>\n",
       "      <td>Josie Rourke</td>\n",
       "      <td>[Josie Rourke]</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.981121</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Who directed the film \"Donkey Punch\"?</td>\n",
       "      <td>[. turan agreed that mendes'choice of collabor...</td>\n",
       "      <td>Oliver Blackburn.</td>\n",
       "      <td>[Olly Blackburn.]</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707491</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.950973</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is Du Fu known for writing extensively ab...</td>\n",
       "      <td>[criticism of du fu's works has focused on his...</td>\n",
       "      <td>Lushi.</td>\n",
       "      <td>[Domestic life, calligraphy, paintings, animals.]</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.961328</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.803045</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Which chart did \"Kiss You\" debut on in the Uni...</td>\n",
       "      <td>[. it peaked at number 13 in its third and fou...</td>\n",
       "      <td>Billboard</td>\n",
       "      <td>[United States Billboard Hot 100.]</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.799624</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.877977</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Who held the Vevo record for the most views in...</td>\n",
       "      <td>[the music video garnered 10 @. @ 4 million vi...</td>\n",
       "      <td>Justin Bieber.</td>\n",
       "      <td>[Justin Bieber]</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.947051</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.957363</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Who ordered No. 202 Squadron RAF to Gibraltar?</td>\n",
       "      <td>[. the raf dispatched their next squadron to g...</td>\n",
       "      <td>No. 202 Squadron RAF was ordered to Gibraltar.</td>\n",
       "      <td>[Admiralty]</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.939381</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.775491</td>\n",
       "      <td>0.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Who was the senior tunnel guide with the Royal...</td>\n",
       "      <td>[work in gibraltar began immediately under com...</td>\n",
       "      <td>Pete Jackson.</td>\n",
       "      <td>[Sergeant Major Pete Jackson.]</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.945070</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.902460</td>\n",
       "      <td>0.071429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Who was the Roman Emperor after Nerva?</td>\n",
       "      <td>[nerva ( latin : marcus cocceius nerva caesar ...</td>\n",
       "      <td>Trajan</td>\n",
       "      <td>[Trajan]</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.941410</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Who was proclaimed emperor after the assassina...</td>\n",
       "      <td>[on 18 september, 96, domitian was assassinate...</td>\n",
       "      <td>Marcus Cocceius Nerva</td>\n",
       "      <td>[Marcus Cocceius Nerva.]</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.980902</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.986040</td>\n",
       "      <td>0.105263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Who does Eddie meet at the local bus terminal?</td>\n",
       "      <td>[. as a radio broadcaster, he is remembered fo...</td>\n",
       "      <td>Sarah Packard</td>\n",
       "      <td>[Sarah Packard]</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.725248</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             question  \\\n",
       "0       Who directed the play \"How to Curse\" in 2007?   \n",
       "1               Who directed the film \"Donkey Punch\"?   \n",
       "2   What is Du Fu known for writing extensively ab...   \n",
       "3   Which chart did \"Kiss You\" debut on in the Uni...   \n",
       "4   Who held the Vevo record for the most views in...   \n",
       "..                                                ...   \n",
       "82     Who ordered No. 202 Squadron RAF to Gibraltar?   \n",
       "83  Who was the senior tunnel guide with the Royal...   \n",
       "84             Who was the Roman Emperor after Nerva?   \n",
       "85  Who was proclaimed emperor after the assassina...   \n",
       "86     Who does Eddie meet at the local bus terminal?   \n",
       "\n",
       "                                             contexts  \\\n",
       "0   [in 2006, boulter starred alongside whishaw in...   \n",
       "1   [. turan agreed that mendes'choice of collabor...   \n",
       "2   [criticism of du fu's works has focused on his...   \n",
       "3   [. it peaked at number 13 in its third and fou...   \n",
       "4   [the music video garnered 10 @. @ 4 million vi...   \n",
       "..                                                ...   \n",
       "82  [. the raf dispatched their next squadron to g...   \n",
       "83  [work in gibraltar began immediately under com...   \n",
       "84  [nerva ( latin : marcus cocceius nerva caesar ...   \n",
       "85  [on 18 september, 96, domitian was assassinate...   \n",
       "86  [. as a radio broadcaster, he is remembered fo...   \n",
       "\n",
       "                                            answer  \\\n",
       "0                                     Josie Rourke   \n",
       "1                                Oliver Blackburn.   \n",
       "2                                           Lushi.   \n",
       "3                                        Billboard   \n",
       "4                                   Justin Bieber.   \n",
       "..                                             ...   \n",
       "82  No. 202 Squadron RAF was ordered to Gibraltar.   \n",
       "83                                   Pete Jackson.   \n",
       "84                                          Trajan   \n",
       "85                           Marcus Cocceius Nerva   \n",
       "86                                   Sarah Packard   \n",
       "\n",
       "                                        ground_truths  context_precision  \\\n",
       "0                                      [Josie Rourke]               1.00   \n",
       "1                                   [Olly Blackburn.]               0.00   \n",
       "2   [Domestic life, calligraphy, paintings, animals.]               0.20   \n",
       "3                  [United States Billboard Hot 100.]               0.00   \n",
       "4                                     [Justin Bieber]               1.00   \n",
       "..                                                ...                ...   \n",
       "82                                        [Admiralty]               1.00   \n",
       "83                     [Sergeant Major Pete Jackson.]               0.20   \n",
       "84                                           [Trajan]               0.25   \n",
       "85                           [Marcus Cocceius Nerva.]               1.00   \n",
       "86                                    [Sarah Packard]               0.20   \n",
       "\n",
       "    faithfulness  answer_relevancy  context_recall  answer_similarity  \\\n",
       "0            1.0          0.981121             1.0           0.999998   \n",
       "1            0.0          0.707491             0.0           0.950973   \n",
       "2            1.0          0.961328             0.0           0.803045   \n",
       "3            0.0          0.799624             0.0           0.877977   \n",
       "4            1.0          0.947051             1.0           0.957363   \n",
       "..           ...               ...             ...                ...   \n",
       "82           1.0          0.939381             1.0           0.775491   \n",
       "83           0.0          0.945070             1.0           0.902460   \n",
       "84           1.0          0.941410             1.0           1.000000   \n",
       "85           1.0          0.980902             1.0           0.986040   \n",
       "86           1.0          0.725248             1.0           1.000000   \n",
       "\n",
       "    context_relevancy  \n",
       "0            0.111111  \n",
       "1            0.000000  \n",
       "2            0.100000  \n",
       "3            0.000000  \n",
       "4            0.000000  \n",
       "..                ...  \n",
       "82           0.062500  \n",
       "83           0.071429  \n",
       "84           0.076923  \n",
       "85           0.105263  \n",
       "86           0.055556  \n",
       "\n",
       "[87 rows x 10 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mprasadshreyas\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/sudhanva/code/takehome/wandb/run-20240129_165623-9qhuvegl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/prasadshreyas/wikitext-rag-eval/runs/9qhuvegl' target=\"_blank\">flowing-surf-1</a></strong> to <a href='https://wandb.ai/prasadshreyas/wikitext-rag-eval' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/prasadshreyas/wikitext-rag-eval' target=\"_blank\">https://wandb.ai/prasadshreyas/wikitext-rag-eval</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/prasadshreyas/wikitext-rag-eval/runs/9qhuvegl' target=\"_blank\">https://wandb.ai/prasadshreyas/wikitext-rag-eval/runs/9qhuvegl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b222bb88ae844aadbc6d2ef79e4012d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.020 MB of 0.020 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>answer_relevancy</td><td>▁</td></tr><tr><td>answer_similarity</td><td>▁</td></tr><tr><td>context_precision</td><td>▁</td></tr><tr><td>context_recall</td><td>▁</td></tr><tr><td>context_relevancy</td><td>▁</td></tr><tr><td>faithfulness</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>answer_relevancy</td><td>0.85442</td></tr><tr><td>answer_similarity</td><td>0.91238</td></tr><tr><td>context_precision</td><td>0.59906</td></tr><tr><td>context_recall</td><td>0.78352</td></tr><tr><td>context_relevancy</td><td>0.11154</td></tr><tr><td>faithfulness</td><td>0.71264</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">flowing-surf-1</strong> at: <a href='https://wandb.ai/prasadshreyas/wikitext-rag-eval/runs/9qhuvegl' target=\"_blank\">https://wandb.ai/prasadshreyas/wikitext-rag-eval/runs/9qhuvegl</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240129_165623-9qhuvegl/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Logging to wandb\n",
    "\n",
    "import wandb\n",
    "\n",
    "# start a new wandb run to track this script\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"wikitext-rag-eval\",\n",
    "    \n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "        \"number_of_questions\": len(ds),\n",
    "        \"comments\": \"Simple QA RAG model with no teleprompter\",\n",
    "        \"model\": \"RAG\",\n",
    "        \"dataset\": \"Synthetic\",\n",
    "        \"num_passages\": 5,\n",
    "        \"openai_model\": \"gpt-3.5-turbo\",\n",
    "        \"chroma_collection_name\": \"test\",\n",
    "        \"chroma_persist_directory\": \"chroma.db\",\n",
    "        \"chroma_local_embed_model\": \"sentence-transformers/paraphrase-MiniLM-L6-v2\",\n",
    "\n",
    "    }\n",
    ")\n",
    "\n",
    "wandb.log(result)\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's compile the RAG using teleprompters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>ground_truths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What instruments did Thomas Newman mainly use ...</td>\n",
       "      <td>['Percussion instruments.']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Who led the Praetorian Guard in the siege of t...</td>\n",
       "      <td>['Casperius Aelianus.']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Where is San Lorenzo Colossal Head 2 currently...</td>\n",
       "      <td>['Mexico City.']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Who praised Coleman and the new side of the Do...</td>\n",
       "      <td>[\"The Mirror's Jon Cooper.\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q: What was the North Korean strategy during t...</td>\n",
       "      <td>['A: Double envelopment of flanks.']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What were the effects of Typhoon Kujira in Japan?</td>\n",
       "      <td>['Agricultural damage and fatalities.']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Q: What was the name of the village located at...</td>\n",
       "      <td>['A: Agok.']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Q1: When were the sisters Ise and Hyūga transf...</td>\n",
       "      <td>['A1: 1 May 1944.']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Who was Nero's mother?</td>\n",
       "      <td>['Agrippina.']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What was the peak wind gust on Chichi-jima dur...</td>\n",
       "      <td>['200 km/h (124 mph)']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What instruments did Thomas Newman mainly use ...   \n",
       "1  Who led the Praetorian Guard in the siege of t...   \n",
       "2  Where is San Lorenzo Colossal Head 2 currently...   \n",
       "3  Who praised Coleman and the new side of the Do...   \n",
       "4  Q: What was the North Korean strategy during t...   \n",
       "5  What were the effects of Typhoon Kujira in Japan?   \n",
       "6  Q: What was the name of the village located at...   \n",
       "7  Q1: When were the sisters Ise and Hyūga transf...   \n",
       "8                             Who was Nero's mother?   \n",
       "9  What was the peak wind gust on Chichi-jima dur...   \n",
       "\n",
       "                             ground_truths  \n",
       "0              ['Percussion instruments.']  \n",
       "1                  ['Casperius Aelianus.']  \n",
       "2                         ['Mexico City.']  \n",
       "3             [\"The Mirror's Jon Cooper.\"]  \n",
       "4     ['A: Double envelopment of flanks.']  \n",
       "5  ['Agricultural damage and fatalities.']  \n",
       "6                             ['A: Agok.']  \n",
       "7                      ['A1: 1 May 1944.']  \n",
       "8                           ['Agrippina.']  \n",
       "9                   ['200 km/h (124 mph)']  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "trainset = []\n",
    "for i in range(5):\n",
    "    ex = dspy.Example(\n",
    "        question=train['question'].iloc[i],\n",
    "        answer=ast.literal_eval(train['ground_truths'].iloc[i])[0]\n",
    "    )\n",
    "    ex = ex.with_inputs('question')\n",
    "    trainset.append(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Example({'question': 'What instruments did Thomas Newman mainly use to create the score for American Beauty?', 'answer': 'Percussion instruments.'}) (input_keys={'question'}),\n",
       " Example({'question': 'Who led the Praetorian Guard in the siege of the Imperial Palace?', 'answer': 'Casperius Aelianus.'}) (input_keys={'question'}),\n",
       " Example({'question': 'Where is San Lorenzo Colossal Head 2 currently located?', 'answer': 'Mexico City.'}) (input_keys={'question'}),\n",
       " Example({'question': 'Who praised Coleman and the new side of the Doctor in \"The Snowmen\"?', 'answer': \"The Mirror's Jon Cooper.\"}) (input_keys={'question'}),\n",
       " Example({'question': 'Q: What was the North Korean strategy during the Korean War?', 'answer': 'A: Double envelopment of flanks.'}) (input_keys={'question'})]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:06<00:00,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 5 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from dspy.teleprompt import BootstrapFewShot\n",
    "\n",
    "# Validation logic: check that the predicted answer is correct.\n",
    "# Also check that the retrieved context does actually contain that answer.\n",
    "def validate_context_and_answer(example, pred, trace=None):\n",
    "    answer_EM = dspy.evaluate.answer_exact_match(example, pred)\n",
    "    answer_PM = dspy.evaluate.answer_passage_match(example, pred)\n",
    "    return answer_EM and answer_PM\n",
    "\n",
    "# Set up a basic teleprompter, which will compile our RAG program.\n",
    "teleprompter = BootstrapFewShot(metric=validate_context_and_answer)\n",
    "\n",
    "# Compile!\n",
    "compiled_rag = teleprompter.compile(RAG(), trainset=trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "def get_evals(dataset, rag):\n",
    "    # Create an empty list to store rows\n",
    "    eval_results_rows = []\n",
    "\n",
    "    for index, row in dataset.iterrows():\n",
    "        # Get the question\n",
    "        question = row['question']\n",
    "        # Response from rag\n",
    "        response = rag(question)\n",
    "        # Create a dictionary to represent a row\n",
    "        row_dict = {'question': question, 'contexts': response.context, 'answer': response.answer, 'ground_truths' : row['ground_truths']}\n",
    "        # Append the row dictionary to the list\n",
    "        eval_results_rows.append(row_dict)\n",
    "\n",
    "    # Create the df_eval_results DataFrame from the list of rows\n",
    "    df_eval_results = pd.DataFrame(eval_results_rows)\n",
    "\n",
    "    # Convert 'ground_truths' column to list\n",
    "    df_eval_results['ground_truths'] = df_eval_results['ground_truths'].apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "    return df_eval_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_eval_results = get_evals(test, compiled_rag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the df_eval_results DataFrame to a csv file\n",
    "import time\n",
    "EXP_NAME = \"COMPILED_RAG\"\n",
    "TIMESTAMP = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "df_eval_results.to_csv('./results/inference_' + EXP_NAME + '_' + TIMESTAMP + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, that we have answers for all the questions, we can evaluate the RAG model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [context_precision]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:22<00:00,  3.79s/it]\n",
      "/home/sudhanva/miniconda3/lib/python3.11/site-packages/datasets/table.py:1395: FutureWarning: promote has been superseded by mode='default'.\n",
      "  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]\n",
      "/home/sudhanva/miniconda3/lib/python3.11/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [faithfulness]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:30<00:00,  5.15s/it]\n",
      "/home/sudhanva/miniconda3/lib/python3.11/site-packages/datasets/table.py:1395: FutureWarning: promote has been superseded by mode='default'.\n",
      "  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]\n",
      "/home/sudhanva/miniconda3/lib/python3.11/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [answer_relevancy]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:52<00:00,  8.80s/it]\n",
      "/home/sudhanva/miniconda3/lib/python3.11/site-packages/datasets/table.py:1395: FutureWarning: promote has been superseded by mode='default'.\n",
      "  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]\n",
      "/home/sudhanva/miniconda3/lib/python3.11/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [context_recall]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:13<00:00,  2.27s/it]\n",
      "/home/sudhanva/miniconda3/lib/python3.11/site-packages/datasets/table.py:1395: FutureWarning: promote has been superseded by mode='default'.\n",
      "  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]\n",
      "/home/sudhanva/miniconda3/lib/python3.11/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [answer_similarity]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.58it/s]\n",
      "/home/sudhanva/miniconda3/lib/python3.11/site-packages/datasets/table.py:1395: FutureWarning: promote has been superseded by mode='default'.\n",
      "  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]\n",
      "/home/sudhanva/miniconda3/lib/python3.11/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [context_relevancy]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:13<00:00,  2.23s/it]\n",
      "/home/sudhanva/miniconda3/lib/python3.11/site-packages/datasets/table.py:1395: FutureWarning: promote has been superseded by mode='default'.\n",
      "  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]\n",
      "/home/sudhanva/miniconda3/lib/python3.11/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    }
   ],
   "source": [
    "ds = Dataset.from_pandas(df_eval_results)\n",
    "\n",
    "result = evaluate(\n",
    "    ds,\n",
    "    metrics=[\n",
    "        context_precision,\n",
    "        faithfulness,\n",
    "        answer_relevancy,\n",
    "        context_recall,\n",
    "        answer_similarity,\n",
    "        context_relevancy\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context_precision': 0.5905, 'faithfulness': 0.7500, 'answer_relevancy': 0.8759, 'context_recall': 0.7694, 'answer_similarity': 0.9061, 'context_relevancy': 0.1104}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the result\n",
    "result.to_pandas().to_csv('./results/evaluation_' + EXP_NAME + '_' + TIMESTAMP + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sudhanva/miniconda3/lib/python3.11/site-packages/datasets/table.py:1395: FutureWarning: promote has been superseded by mode='default'.\n",
      "  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]\n",
      "/home/sudhanva/miniconda3/lib/python3.11/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>contexts</th>\n",
       "      <th>answer</th>\n",
       "      <th>ground_truths</th>\n",
       "      <th>context_precision</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>context_recall</th>\n",
       "      <th>answer_similarity</th>\n",
       "      <th>context_relevancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What type of teeth do temnospondyls have on th...</td>\n",
       "      <td>[unlike semiaquatic temnospondyls, terrestrial...</td>\n",
       "      <td>Teeth.</td>\n",
       "      <td>[Tusks.]</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.878008</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.855351</td>\n",
       "      <td>0.210526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Who were the Principal Architects for Palestin...</td>\n",
       "      <td>[= = = architects and sculptors = = = as well ...</td>\n",
       "      <td>Sir John James Burnet.</td>\n",
       "      <td>[Sir John James Burnet and Thomas Smith Tait.]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.975334</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.946708</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the title of Brock Lesnar's autobiogra...</td>\n",
       "      <td>[in 2009, lesnar signed an endorsement deal wi...</td>\n",
       "      <td>Death Clutch.</td>\n",
       "      <td>[Death Clutch]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989006</td>\n",
       "      <td>0.071429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Where is the replica of San Lorenzo Head 8 loc...</td>\n",
       "      <td>[san francisco, california. a replica of san l...</td>\n",
       "      <td>West Valley City, Utah.</td>\n",
       "      <td>[Utah Cultural Celebration Center.]</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.723326</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.853857</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What was the main flaw in the design of the Fu...</td>\n",
       "      <td>[the progress of fuso's construction, while th...</td>\n",
       "      <td>Distribution of midships gun turrets.</td>\n",
       "      <td>[Midships gun turrets.]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.961188</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.958398</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Q: How many Marines and Navy SEALs were part o...</td>\n",
       "      <td>[. the marines were to be released from 2nd di...</td>\n",
       "      <td>60.</td>\n",
       "      <td>[A: 51 Marines and 9 Navy SEALs.]</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.820366</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.770896</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>What is the estimated weight of the La Cobata ...</td>\n",
       "      <td>[the la cobata head is more or less rounded an...</td>\n",
       "      <td>40 tons.</td>\n",
       "      <td>[40 tons.]</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.974329</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.107143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>What is the name of the group of temnospondyls...</td>\n",
       "      <td>[temnospondyls, like all amphibians, reproduce...</td>\n",
       "      <td>Stereospondyli.</td>\n",
       "      <td>[Stereospondyli.]</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.951946</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Who promoted Brad Stevens to a full-time assis...</td>\n",
       "      <td>[. within 24 hours of the interviews stevens w...</td>\n",
       "      <td>Todd Lickliter.</td>\n",
       "      <td>[Todd Lickliter.]</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.841781</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>What is the population of Manila according to ...</td>\n",
       "      <td>[manila is the second most populous city in th...</td>\n",
       "      <td>1,780,148.</td>\n",
       "      <td>[1,780,148.]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.959739</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.052632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             question  \\\n",
       "0   What type of teeth do temnospondyls have on th...   \n",
       "1   Who were the Principal Architects for Palestin...   \n",
       "2   What is the title of Brock Lesnar's autobiogra...   \n",
       "3   Where is the replica of San Lorenzo Head 8 loc...   \n",
       "4   What was the main flaw in the design of the Fu...   \n",
       "..                                                ...   \n",
       "81  Q: How many Marines and Navy SEALs were part o...   \n",
       "82  What is the estimated weight of the La Cobata ...   \n",
       "83  What is the name of the group of temnospondyls...   \n",
       "84  Who promoted Brad Stevens to a full-time assis...   \n",
       "85  What is the population of Manila according to ...   \n",
       "\n",
       "                                             contexts  \\\n",
       "0   [unlike semiaquatic temnospondyls, terrestrial...   \n",
       "1   [= = = architects and sculptors = = = as well ...   \n",
       "2   [in 2009, lesnar signed an endorsement deal wi...   \n",
       "3   [san francisco, california. a replica of san l...   \n",
       "4   [the progress of fuso's construction, while th...   \n",
       "..                                                ...   \n",
       "81  [. the marines were to be released from 2nd di...   \n",
       "82  [the la cobata head is more or less rounded an...   \n",
       "83  [temnospondyls, like all amphibians, reproduce...   \n",
       "84  [. within 24 hours of the interviews stevens w...   \n",
       "85  [manila is the second most populous city in th...   \n",
       "\n",
       "                                   answer  \\\n",
       "0                                  Teeth.   \n",
       "1                  Sir John James Burnet.   \n",
       "2                           Death Clutch.   \n",
       "3                 West Valley City, Utah.   \n",
       "4   Distribution of midships gun turrets.   \n",
       "..                                    ...   \n",
       "81                                    60.   \n",
       "82                               40 tons.   \n",
       "83                        Stereospondyli.   \n",
       "84                        Todd Lickliter.   \n",
       "85                             1,780,148.   \n",
       "\n",
       "                                     ground_truths  context_precision  \\\n",
       "0                                         [Tusks.]           0.416667   \n",
       "1   [Sir John James Burnet and Thomas Smith Tait.]           1.000000   \n",
       "2                                   [Death Clutch]           1.000000   \n",
       "3              [Utah Cultural Celebration Center.]           0.866667   \n",
       "4                          [Midships gun turrets.]           1.000000   \n",
       "..                                             ...                ...   \n",
       "81               [A: 51 Marines and 9 Navy SEALs.]           0.500000   \n",
       "82                                      [40 tons.]           0.700000   \n",
       "83                               [Stereospondyli.]           0.500000   \n",
       "84                               [Todd Lickliter.]           0.500000   \n",
       "85                                    [1,780,148.]           1.000000   \n",
       "\n",
       "    faithfulness  answer_relevancy  context_recall  answer_similarity  \\\n",
       "0            1.0          0.878008        0.750000           0.855351   \n",
       "1            1.0          0.975334        1.000000           0.946708   \n",
       "2            1.0          1.000000        1.000000           0.989006   \n",
       "3            1.0          0.723326        1.000000           0.853857   \n",
       "4            1.0          0.961188        1.000000           0.958398   \n",
       "..           ...               ...             ...                ...   \n",
       "81           1.0          0.820366        0.333333           0.770896   \n",
       "82           1.0          0.974329        1.000000           1.000000   \n",
       "83           1.0          0.951946        1.000000           1.000000   \n",
       "84           1.0          0.841781        1.000000           1.000000   \n",
       "85           1.0          0.959739        1.000000           1.000000   \n",
       "\n",
       "    context_relevancy  \n",
       "0            0.210526  \n",
       "1            0.090909  \n",
       "2            0.071429  \n",
       "3            0.000000  \n",
       "4            0.100000  \n",
       "..                ...  \n",
       "81           0.000000  \n",
       "82           0.107143  \n",
       "83           0.055556  \n",
       "84           0.055556  \n",
       "85           0.052632  \n",
       "\n",
       "[86 rows x 10 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48a35b677d1741bdaa77d73a4d982dd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011114155201034414, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/sudhanva/code/takehome/wandb/run-20240129_172412-0jroncen</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/prasadshreyas/wikitext-rag-eval/runs/0jroncen' target=\"_blank\">robust-serenity-2</a></strong> to <a href='https://wandb.ai/prasadshreyas/wikitext-rag-eval' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/prasadshreyas/wikitext-rag-eval' target=\"_blank\">https://wandb.ai/prasadshreyas/wikitext-rag-eval</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/prasadshreyas/wikitext-rag-eval/runs/0jroncen' target=\"_blank\">https://wandb.ai/prasadshreyas/wikitext-rag-eval/runs/0jroncen</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "124b54a511eb47bcab3441500e016c83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.020 MB of 0.020 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>answer_relevancy</td><td>▁</td></tr><tr><td>answer_similarity</td><td>▁</td></tr><tr><td>context_precision</td><td>▁</td></tr><tr><td>context_recall</td><td>▁</td></tr><tr><td>context_relevancy</td><td>▁</td></tr><tr><td>faithfulness</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>answer_relevancy</td><td>0.8759</td></tr><tr><td>answer_similarity</td><td>0.90609</td></tr><tr><td>context_precision</td><td>0.59052</td></tr><tr><td>context_recall</td><td>0.76938</td></tr><tr><td>context_relevancy</td><td>0.11039</td></tr><tr><td>faithfulness</td><td>0.75</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">robust-serenity-2</strong> at: <a href='https://wandb.ai/prasadshreyas/wikitext-rag-eval/runs/0jroncen' target=\"_blank\">https://wandb.ai/prasadshreyas/wikitext-rag-eval/runs/0jroncen</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240129_172412-0jroncen/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Logging to wandb\n",
    "\n",
    "# start a new wandb run to track this script\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"wikitext-rag-eval\",\n",
    "    \n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "        \"number_of_questions\": len(ds),\n",
    "        \"comments\": \"Compiled QA RAG model with teleprompter\",\n",
    "        \"model\": \"RAG\",\n",
    "        \"dataset\": \"Synthetic\",\n",
    "        \"num_passages\": 5,\n",
    "        \"openai_model\": \"gpt-3.5-turbo\",\n",
    "        \"chroma_collection_name\": \"test\",\n",
    "        \"chroma_persist_directory\": \"chroma.db\",\n",
    "        \"chroma_local_embed_model\": \"sentence-transformers/paraphrase-MiniLM-L6-v2\",\n",
    "\n",
    "    }\n",
    ")\n",
    "\n",
    "wandb.log(result)\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No Retrieval\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicQA(dspy.Signature):\n",
    "    \"\"\"Answer questions with short factoid answers.\"\"\"\n",
    "\n",
    "    question = dspy.InputField()\n",
    "    answer = dspy.OutputField(desc=\"often between 1 and 5 words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the predictor.\n",
    "generate_answer = dspy.Predict(BasicQA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results_rows = []\n",
    "\n",
    "for index, row in test.iterrows():\n",
    "    # Get the question\n",
    "    question = row['question']\n",
    "    # Response from rag\n",
    "    response = generate_answer(question = question)\n",
    "    # Create a dictionary to represent a row\n",
    "    row_dict = {'question': question, 'answer': response.answer, 'ground_truths' : row['ground_truths']}\n",
    "    # Append the row dictionary to the list\n",
    "    eval_results_rows.append(row_dict)\n",
    "\n",
    "# Create the df_eval_results DataFrame from the list of rows\n",
    "df_eval_results = pd.DataFrame(eval_results_rows)\n",
    "\n",
    "# Convert 'ground_truths' column to list\n",
    "df_eval_results['ground_truths'] = df_eval_results['ground_truths'].apply(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [answer_similarity]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.59it/s]\n",
      "/home/sudhanva/miniconda3/lib/python3.11/site-packages/datasets/table.py:1395: FutureWarning: promote has been superseded by mode='default'.\n",
      "  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]\n",
      "/home/sudhanva/miniconda3/lib/python3.11/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    }
   ],
   "source": [
    "ds = Dataset.from_pandas(df_eval_results)\n",
    "\n",
    "result = evaluate(\n",
    "    ds,\n",
    "    metrics=[\n",
    "        answer_similarity\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer_similarity': 0.8535}"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the result\n",
    "result.to_pandas().to_csv('./results/evaluation_' + EXP_NAME + '_' + TIMESTAMP + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sudhanva/miniconda3/lib/python3.11/site-packages/datasets/table.py:1395: FutureWarning: promote has been superseded by mode='default'.\n",
      "  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]\n",
      "/home/sudhanva/miniconda3/lib/python3.11/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>ground_truths</th>\n",
       "      <th>answer_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What type of teeth do temnospondyls have on th...</td>\n",
       "      <td>Conical teeth</td>\n",
       "      <td>[Tusks.]</td>\n",
       "      <td>0.815168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Who were the Principal Architects for Palestin...</td>\n",
       "      <td>Sir Ronald Storrs and Sir William Fisher</td>\n",
       "      <td>[Sir John James Burnet and Thomas Smith Tait.]</td>\n",
       "      <td>0.844589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the title of Brock Lesnar's autobiogra...</td>\n",
       "      <td>Death Clutch</td>\n",
       "      <td>[Death Clutch]</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Where is the replica of San Lorenzo Head 8 loc...</td>\n",
       "      <td>Museo Nacional de Antropología, Mexico City</td>\n",
       "      <td>[Utah Cultural Celebration Center.]</td>\n",
       "      <td>0.809204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What was the main flaw in the design of the Fu...</td>\n",
       "      <td>Weak armor</td>\n",
       "      <td>[Midships gun turrets.]</td>\n",
       "      <td>0.792137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Q: How many Marines and Navy SEALs were part o...</td>\n",
       "      <td>A: 30</td>\n",
       "      <td>[A: 51 Marines and 9 Navy SEALs.]</td>\n",
       "      <td>0.803497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>What is the estimated weight of the La Cobata ...</td>\n",
       "      <td>Approximately 20 tons.</td>\n",
       "      <td>[40 tons.]</td>\n",
       "      <td>0.878407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>What is the name of the group of temnospondyls...</td>\n",
       "      <td>Metoposaurids</td>\n",
       "      <td>[Stereospondyli.]</td>\n",
       "      <td>0.824162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Who promoted Brad Stevens to a full-time assis...</td>\n",
       "      <td>Doc Rivers</td>\n",
       "      <td>[Todd Lickliter.]</td>\n",
       "      <td>0.790983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>What is the population of Manila according to ...</td>\n",
       "      <td>1,780,148</td>\n",
       "      <td>[1,780,148.]</td>\n",
       "      <td>0.984600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             question  \\\n",
       "0   What type of teeth do temnospondyls have on th...   \n",
       "1   Who were the Principal Architects for Palestin...   \n",
       "2   What is the title of Brock Lesnar's autobiogra...   \n",
       "3   Where is the replica of San Lorenzo Head 8 loc...   \n",
       "4   What was the main flaw in the design of the Fu...   \n",
       "..                                                ...   \n",
       "81  Q: How many Marines and Navy SEALs were part o...   \n",
       "82  What is the estimated weight of the La Cobata ...   \n",
       "83  What is the name of the group of temnospondyls...   \n",
       "84  Who promoted Brad Stevens to a full-time assis...   \n",
       "85  What is the population of Manila according to ...   \n",
       "\n",
       "                                         answer  \\\n",
       "0                                 Conical teeth   \n",
       "1      Sir Ronald Storrs and Sir William Fisher   \n",
       "2                                  Death Clutch   \n",
       "3   Museo Nacional de Antropología, Mexico City   \n",
       "4                                    Weak armor   \n",
       "..                                          ...   \n",
       "81                                        A: 30   \n",
       "82                       Approximately 20 tons.   \n",
       "83                                Metoposaurids   \n",
       "84                                   Doc Rivers   \n",
       "85                                    1,780,148   \n",
       "\n",
       "                                     ground_truths  answer_similarity  \n",
       "0                                         [Tusks.]           0.815168  \n",
       "1   [Sir John James Burnet and Thomas Smith Tait.]           0.844589  \n",
       "2                                   [Death Clutch]           1.000000  \n",
       "3              [Utah Cultural Celebration Center.]           0.809204  \n",
       "4                          [Midships gun turrets.]           0.792137  \n",
       "..                                             ...                ...  \n",
       "81               [A: 51 Marines and 9 Navy SEALs.]           0.803497  \n",
       "82                                      [40 tons.]           0.878407  \n",
       "83                               [Stereospondyli.]           0.824162  \n",
       "84                               [Todd Lickliter.]           0.790983  \n",
       "85                                    [1,780,148.]           0.984600  \n",
       "\n",
       "[86 rows x 4 columns]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/sudhanva/code/takehome/wandb/run-20240129_175403-d05oa4z7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/prasadshreyas/wikitext-rag-eval/runs/d05oa4z7' target=\"_blank\">balmy-puddle-3</a></strong> to <a href='https://wandb.ai/prasadshreyas/wikitext-rag-eval' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/prasadshreyas/wikitext-rag-eval' target=\"_blank\">https://wandb.ai/prasadshreyas/wikitext-rag-eval</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/prasadshreyas/wikitext-rag-eval/runs/d05oa4z7' target=\"_blank\">https://wandb.ai/prasadshreyas/wikitext-rag-eval/runs/d05oa4z7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cef690affacc401e839cd73683f42f69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.020 MB of 0.020 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>answer_similarity</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>answer_similarity</td><td>0.85353</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">balmy-puddle-3</strong> at: <a href='https://wandb.ai/prasadshreyas/wikitext-rag-eval/runs/d05oa4z7' target=\"_blank\">https://wandb.ai/prasadshreyas/wikitext-rag-eval/runs/d05oa4z7</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240129_175403-d05oa4z7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Logging to wandb\n",
    "\n",
    "# start a new wandb run to track this script\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"wikitext-rag-eval\",\n",
    "    \n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "        \"number_of_questions\": len(ds),\n",
    "        \"comments\": \"No RAG model\",\n",
    "        \"model\": \"RAG\",\n",
    "        \"dataset\": \"Synthetic\",\n",
    "        \"num_passages\": 5,\n",
    "        \"openai_model\": \"gpt-3.5-turbo\",\n",
    "        \"chroma_collection_name\": \"test\",\n",
    "        \"chroma_persist_directory\": \"chroma.db\",\n",
    "        \"chroma_local_embed_model\": \"sentence-transformers/paraphrase-MiniLM-L6-v2\",\n",
    "\n",
    "    }\n",
    ")\n",
    "\n",
    "wandb.log(result)\n",
    "\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
